import streamlit as st
import pandas as pd
import numpy as np
import os
import glob
import requests
import zipfile
import io
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import time
from datetime import datetime

# Diret√≥rio para armazenar os dados descompactados
DATA_DIR = 'streamlit_data'
ZIP_URL = "http://www.dpi.inpe.br/amb_data/AmericaSul/SAmerica_WCLIM.zip"
ZIP_FILENAME = "SAmerica_WCLIM.zip"
LOG_FILE = os.path.join(DATA_DIR, "model_creation.log")

# --- Sistema de Download e Processamento (Atualizado) ---

def check_data_status(data_dir, zip_filename):
    """Verifica o status dos dados e processamento"""
    dir_exists = os.path.exists(data_dir)
    zip_exists = os.path.exists(os.path.join(data_dir, zip_filename))
    log_exists = os.path.exists(LOG_FILE)
    
    status = {
        'dir_exists': dir_exists,
        'zip_exists': zip_exists,
        'log_exists': log_exists,
        'model_created': False
    }
    
    # Verificar se o modelo j√° foi criado
    if log_exists:
        try:
            with open(LOG_FILE, 'r') as f:
                log_content = f.read()
            status['model_created'] = 'CREATED: TRUE' in log_content.upper()
        except:
            status['model_created'] = False
    
    return status

def download_zip_file(url, target_dir, zip_filename):
    """Faz download do arquivo ZIP com feedback de progresso"""
    try:
        # Criar diret√≥rio se n√£o existir
        os.makedirs(target_dir, exist_ok=True)
        
        st.info("üåê Iniciando download dos dados...")
        progress_bar = st.progress(0)
        
        # Download
        response = requests.get(url, stream=True, timeout=60)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded_size = 0
        chunk_size = 8192
        
        temp_zip = os.path.join(target_dir, f"temp_{zip_filename}")
        
        with open(temp_zip, 'wb') as f:
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:
                    f.write(chunk)
                    downloaded_size += len(chunk)
                    if total_size > 0:
                        progress = downloaded_size / total_size
                        progress_bar.progress(min(progress, 1.0))
        
        # Mover para nome final
        target_zip = os.path.join(target_dir, zip_filename)
        os.rename(temp_zip, target_zip)
        
        progress_bar.progress(1.0)
        st.success("‚úÖ Download realizado com sucesso!")
        return True
        
    except Exception as e:
        st.error(f"‚ùå Erro durante o download: {e}")
        return False

def unzip_data_file(zip_path, target_dir):
    """Descompacta arquivo ZIP com feedback"""
    try:
        st.info("üì¶ Iniciando descompacta√ß√£o dos dados...")
        progress_bar = st.progress(0)
        
        with zipfile.ZipFile(zip_path, 'r') as zf:
            file_list = zf.namelist()
            total_files = len(file_list)
            
            for i, file in enumerate(file_list):
                zf.extract(file, target_dir)
                progress_bar.progress((i + 1) / total_files)
        
        st.success("‚úÖ Dados descompactados com sucesso!")
        return True
        
    except Exception as e:
        st.error(f"‚ùå Erro durante descompacta√ß√£o: {e}")
        return False

def create_model_log(data_dir, status=True):
    """Cria arquivo de log do processamento"""
    try:
        log_content = f"""CREATED: {str(status).upper()}
DATE: {datetime.now()}
DATA_DIR: {data_dir}
TIMESTAMP: {int(time.time())}"""
        
        with open(LOG_FILE, 'w') as f:
            f.write(log_content)
        
        return True
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao criar arquivo de log: {e}")
        return False

def validate_existing_model(data_dir):
    """Valida se o modelo existente est√° completo"""
    if not os.path.exists(LOG_FILE):
        return False
    
    try:
        with open(LOG_FILE, 'r') as f:
            log_content = f.read()
        
        model_created = 'CREATED: TRUE' in log_content.upper()
        
        if model_created:
            # Verificar se os arquivos ASC existem
            asc_files = glob.glob(os.path.join(data_dir, "*.asc"))
            files_to_process = [f for f in asc_files if os.path.basename(f) not in ['alt.asc', 'decl.asc', '110914_DadosWorldClim_SouthAmerica_25.txt']]
            
            if len(files_to_process) > 10:  # Espera-se mais de 10 arquivos clim√°ticos
                st.info("‚úÖ Modelo existente validado. Utilizando dados pr√©-processados.")
                return True
            else:
                st.warning("‚ö†Ô∏è Log encontrado, mas arquivos de dados incompletos. Reprocessando.")
                return False
        else:
            return False
            
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao validar modelo existente: {e}")
        return False

def download_and_process_data(url, target_dir, zip_filename):
    """Fun√ß√£o principal para orquestrar download e processamento"""
    # Verificar status atual
    status = check_data_status(target_dir, zip_filename)
    
    # Se modelo j√° foi criado e validado, retornar TRUE
    if status['model_created'] and validate_existing_model(target_dir):
        return True
    
    # Barra de progresso principal
    progress_placeholder = st.empty()
    progress_bar = st.progress(0)
    
    # Etapa 1: Verificar e baixar dados se necess√°rio
    progress_placeholder.info("üîç Verificando dados existentes...")
    progress_bar.progress(0.1)
    
    if not status['zip_exists'] or not status['dir_exists']:
        progress_placeholder.info("üì• Download necess√°rio. Baixando dados...")
        progress_bar.progress(0.2)
        download_success = download_zip_file(url, target_dir, zip_filename)
        if not download_success:
            return False
    
    # Etapa 2: Descompactar dados
    progress_placeholder.info("üìÇ Preparando para descompactar...")
    progress_bar.progress(0.5)
    zip_path = os.path.join(target_dir, zip_filename)
    unzip_success = unzip_data_file(zip_path, target_dir)
    if not unzip_success:
        return False
    
    # Etapa 3: Criar log do modelo
    progress_placeholder.info("‚öôÔ∏è Finalizando processamento...")
    progress_bar.progress(0.9)
    log_success = create_model_log(target_dir, True)
    
    progress_placeholder.info("‚úÖ Processamento conclu√≠do!")
    progress_bar.progress(1.0)
    
    return True

# --- Fun√ß√µes de Processamento de Dados (Mantidas) ---

def read_asc_file(filepath):
    """L√™ um arquivo ASCII Grid (.asc) e retorna os metadados e os dados"""
    try:
        # Ler cabe√ßalho (6 linhas)
        with open(filepath, 'r') as con:
            header_lines = [con.readline().strip() for _ in range(6)]
        
        header = {}
        for line in header_lines:
            parts = line.split()
            key = parts[0]
            value = int(parts[1]) if key in ['ncols', 'nrows'] else float(parts[1])
            header[key] = value
        
        # Ler dados
        data = np.loadtxt(filepath, skiprows=6)
        
        return {'header': header, 'data': data}
    except Exception as e:
        st.error(f"Erro ao ler arquivo {os.path.basename(filepath)}: {e}")
        return None

@st.cache_data
def process_worldclim_data(data_dir):
    """Processa todos os arquivos WorldClim (.asc) no diret√≥rio"""
    if not os.path.exists(data_dir):
        st.error(f"Diret√≥rio n√£o encontrado: {data_dir}")
        return None
    
    # Listar arquivos .asc, excluindo arquivos n√£o clim√°ticos
    asc_files = glob.glob(os.path.join(data_dir, "*.asc"))
    files_to_process = [f for f in asc_files if os.path.basename(f) not in ['alt.asc', 'decl.asc', '110914_DadosWorldClim_SouthAmerica_25.txt']]
    
    if len(files_to_process) == 0:
        st.warning("Nenhum arquivo .asc de vari√°veis clim√°ticas encontrado")
        return None
    
    all_data = {}
    
    # Processar primeiro arquivo para obter estrutura
    first_file = files_to_process[0]
    first_result = read_asc_file(first_file)
    if first_result is None:
        return None
    
    rows = first_result['header']['nrows']
    cols = first_result['header']['ncols']
    nodata_value = first_result['header'].get('NODATA_value', -9999)
    
    # Adicionar primeiro conjunto de dados
    var_name = os.path.splitext(os.path.basename(first_file))[0]
    all_data[var_name] = first_result['data'].flatten()
    
    # Processar arquivos restantes
    for filepath in files_to_process[1:]:
        result = read_asc_file(filepath)
        if result is None:
            continue
        
        # Verificar dimens√µes
        if result['header']['nrows'] != rows or result['header']['ncols'] != cols:
            st.warning(f"Dimens√µes n√£o correspondem para {os.path.basename(filepath)}")
            continue
        
        var_name = os.path.splitext(os.path.basename(filepath))[0]
        all_data[var_name] = result['data'].flatten()
    
    # Criar DataFrame
    df = pd.DataFrame(all_data)
    
    # Adicionar coordenadas
    df['row'] = np.repeat(range(1, rows + 1), cols)
    df['col'] = np.tile(range(1, cols + 1), rows)
    
    # Reordenar colunas
    df = df[['row', 'col'] + [col for col in df.columns if col not in ['row', 'col']]]
    
    # Remover valores NODATA
    df_clean = df[~(df == nodata_value).any(axis=1)]
    
    return df_clean

# --- UI 1: Administra√ß√£o - Download e Processamento (Atualizada) ---

def ui_administracao():
    st.header("üìä Administra√ß√£o - Download e Processamento de Dados")
    
    st.markdown("""
    Esta se√ß√£o gerencia o download e processamento dos dados clim√°ticos do WorldClim para a Am√©rica do Sul.
    Os dados ser√£o baixados do INPE e processados para an√°lise.
    """)
    
    # Verificar status atual
    status = check_data_status(DATA_DIR, ZIP_FILENAME)
    
    if status['model_created'] and validate_existing_model(DATA_DIR):
        st.success("‚úÖ Modelo e dados prontos para serem visualizados")
        st.info("Os dados j√° foram processados e est√£o dispon√≠veis para an√°lise nas outras se√ß√µes.")
        
        if st.button("üîÑ Reprocessar Dados", type="secondary"):
            # Remove diret√≥rio existente para for√ßar novo processamento
            if os.path.exists(DATA_DIR):
                import shutil
                shutil.rmtree(DATA_DIR)
            st.session_state.dados_processados = False
            st.session_state.df_clean = None
            st.session_state.model = None
            st.session_state.metrics = None
            st.rerun()
    else:
        st.warning("‚ö†Ô∏è Dados n√£o encontrados. √â necess√°rio processar os dados para continuar.")
        
        if st.button("üöÄ Processar Dados", type="primary"):
            st.session_state.processar_dados = True
    
    # Processamento de dados
    if st.session_state.get('processar_dados', False):
        if download_and_process_data(ZIP_URL, DATA_DIR, ZIP_FILENAME):
            df_clean = process_worldclim_data(DATA_DIR)
            if df_clean is not None:
                st.session_state.df_clean = df_clean
                st.session_state.dados_processados = True
                st.session_state.processar_dados = False
                st.rerun()
            else:
                st.error("‚ùå Falha ao processar os dados clim√°ticos.")
        else:
            st.error("‚ùå Falha ao baixar ou descompactar os dados.")

# --- UI 2: An√°lise Estat√≠stica Explorat√≥ria (Atualizada) ---

def ui_analise_estatistica():
    st.header("üìà An√°lise Estat√≠stica Explorat√≥ria")
    
    if 'df_clean' not in st.session_state:
        st.warning("‚ö†Ô∏è Por favor, processe os dados primeiro na se√ß√£o 'Administra√ß√£o'.")
        return
    
    df_clean = st.session_state.df_clean
    
    st.subheader("Vis√£o Geral dos Dados")
    st.write(f"N√∫mero total de pontos de grade v√°lidos: **{len(df_clean):,}**")
    
    # Estat√≠sticas descritivas COMPLETAS com NAs
    st.subheader("Estat√≠sticas Descritivas (Completas)")
    st.write("Estat√≠sticas descritivas para todas as vari√°veis bioclim√°ticas incluindo valores NA:")
    
    bio_cols = [col for col in df_clean.columns if col.startswith('bio')]
    
    # Calcular estat√≠sticas descritivas avan√ßadas
    desc_stats_list = []
    for col in bio_cols:
        stats = {
            'Vari√°vel': col,
            'N': df_clean[col].count(),
            'N_NA': df_clean[col].isna().sum(),
            'Porcentagem_NA': round(df_clean[col].isna().mean() * 100, 2),
            'M√©dia': round(df_clean[col].mean(), 3),
            'Mediana': round(df_clean[col].median(), 3),
            'DP': round(df_clean[col].std(), 3),
            'Min': round(df_clean[col].min(), 3),
            'Q1': round(df_clean[col].quantile(0.25), 3),
            'Q3': round(df_clean[col].quantile(0.75), 3),
            'Max': round(df_clean[col].max(), 3)
        }
        desc_stats_list.append(stats)
    
    desc_stats_df = pd.DataFrame(desc_stats_list)
    st.dataframe(desc_stats_df, use_container_width=True)
    
    # Correla√ß√£o entre vari√°veis bioclim√°ticas
    st.subheader("An√°lise de Correla√ß√£o")
    
    if bio_cols:
        corr_matrix = df_clean[bio_cols].corr()
        
        # Correla√ß√£o com BIO1
        st.markdown("**Correla√ß√£o de BIO1 (Temperatura M√©dia Anual) com Outras Vari√°veis:**")
        corr_bio1 = corr_matrix['bio1'].sort_values(ascending=False).drop('bio1')
        st.dataframe(corr_bio1.to_frame().style.format('{:.4f}'), use_container_width=True)
        
        # Heatmap de correla√ß√£o
        st.markdown("**Mapa de Calor de Correla√ß√µes:**")
        fig, ax = plt.subplots(figsize=(12, 10))
        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=ax)
        ax.set_title('Matriz de Correla√ß√£o - Vari√°veis Bioclim√°ticas')
        st.pyplot(fig)

# --- UI 3: Modelagem (Atualizada com M√©tricas Avan√ßadas) ---

def ui_modelagem():
    st.header("ü§ñ Modelagem: Regress√£o Linear M√∫ltipla")
    st.markdown("**Modelo:** BIO1 (Temperatura M√©dia Anual) ~ BIO12 (Precipita√ß√£o Anual) + BIO4 (Sazonalidade da Temperatura)")
    
    if 'df_clean' not in st.session_state:
        st.warning("‚ö†Ô∏è Por favor, processe os dados primeiro na se√ß√£o 'Administra√ß√£o'.")
        return
    
    if st.button("üéØ Treinar Modelo", type="primary"):
        with st.spinner("Treinando modelo..."):
            df_clean = st.session_state.df_clean
            
            # Preparar dados
            model_df = df_clean[['bio1', 'bio12', 'bio4']].dropna()
            
            # Dividir dados
            X = model_df[['bio12', 'bio4']]
            y = model_df['bio1']
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            # Armazenar conjuntos
            st.session_state.train_data = {'X': X_train, 'y': y_train}
            st.session_state.test_data = {'X': X_test, 'y': y_test}
            
            # Treinar modelo
            model = LinearRegression()
            model.fit(X_train, y_train)
            
            # Fazer previs√µes
            y_pred = model.predict(X_test)
            
            # Calcular m√©tricas avan√ßadas
            r_squared = r2_score(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            
            # Armazenar resultados
            st.session_state.model = model
            st.session_state.predictions = y_pred
            
            st.session_state.metrics = {
                'r_squared': r_squared,
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'coefficients': {
                    'bio12': model.coef_[0],
                    'bio4': model.coef_[1],
                    'intercept': model.intercept_
                },
                'n_train': len(X_train),
                'n_test': len(X_test),
                'n_total': len(model_df)
            }
        
        st.success("‚úÖ Modelo treinado com sucesso!")
    
    # Exibir resultados se o modelo foi treinado
    if st.session_state.get('model') is not None:
        metrics = st.session_state.metrics
        
        # M√©tricas de Avalia√ß√£o
        st.subheader("üìä M√©tricas de Avalia√ß√£o do Modelo")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("R¬≤", f"{metrics['r_squared']:.4f}", 
                     help="Coeficiente de Determina√ß√£o - Propor√ß√£o da vari√¢ncia explicada pelo modelo")
        
        with col2:
            st.metric("MSE", f"{metrics['mse']:.2f}", 
                     help="Erro Quadr√°tico M√©dio - M√©dia dos quadrados dos erros")
        
        with col3:
            st.metric("RMSE", f"{metrics['rmse']:.2f}", 
                     help="Raiz do Erro Quadr√°tico M√©dio - Na mesma unidade da vari√°vel resposta")
        
        with col4:
            st.metric("MAE", f"{metrics['mae']:.2f}", 
                     help="Erro Absoluto M√©dio - M√©dia dos valores absolutos dos erros")
        
        # Estat√≠sticas dos Conjuntos de Dados
        st.subheader("üìà Estat√≠sticas dos Conjuntos de Dados")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Conjunto de Treino", f"{metrics['n_train']:,}", 
                     help="Observa√ß√µes para treinamento")
        
        with col2:
            st.metric("Conjunto de Teste", f"{metrics['n_test']:,}", 
                     help="Observa√ß√µes para teste")
        
        with col3:
            st.metric("Total (Ap√≥s Limpeza)", f"{metrics['n_total']:,}", 
                     help="Observa√ß√µes v√°lidas para modelagem")
        
        # Coeficientes do Modelo
        st.subheader("üîß Coeficientes do Modelo")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Coeficiente BIO12", f"{metrics['coefficients']['bio12']:.4f}", 
                     help="Precipita√ß√£o Anual")
        
        with col2:
            st.metric("Coeficiente BIO4", f"{metrics['coefficients']['bio4']:.4f}", 
                     help="Sazonalidade da Temperatura")
        
        with col3:
            st.metric("Intercepto", f"{metrics['coefficients']['intercept']:.4f}", 
                     help="Termo constante")
        
        # Interpreta√ß√£o do Modelo
        st.subheader("üìã Interpreta√ß√£o do Modelo")
        
        interpretation_text = f"""
        O modelo explica **{metrics['r_squared']*100:.2f}%** da vari√¢ncia na Temperatura M√©dia Anual (BIO1).
        
        üìà Um aumento de 1 unidade em BIO12 (Precipita√ß√£o Anual) est√° associado a uma mudan√ßa de **{metrics['coefficients']['bio12']:.4f}** na BIO1.
        
        üå°Ô∏è Um aumento de 1 unidade em BIO4 (Sazonalidade da Temperatura) est√° associado a uma mudan√ßa de **{metrics['coefficients']['bio4']:.4f}** na BIO1.
        
        üéØ O RMSE de **{metrics['rmse']:.2f}** indica o erro m√©dio de previs√£o do modelo.
        """
        
        st.info(interpretation_text)

# --- UI 4: Visualiza√ß√£o de Dados e Modelo (Atualizada) ---

def ui_visualizacao():
    st.header("üìä Visualiza√ß√£o de Dados e Modelo")
    
    if 'df_clean' not in st.session_state:
        st.warning("‚ö†Ô∏è Por favor, processe os dados primeiro na se√ß√£o 'Administra√ß√£o'.")
        return
    
    df_clean = st.session_state.df_clean
    
    st.subheader("Visualiza√ß√£o dos Dados Clim√°ticos")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Histograma BIO1
        st.markdown("**Distribui√ß√£o da Temperatura M√©dia Anual (BIO1)**")
        fig1, ax1 = plt.subplots()
        sns.histplot(df_clean['bio1'], kde=True, ax=ax1, color='skyblue')
        ax1.set_title('Distribui√ß√£o de BIO1 (Temperatura M√©dia Anual)')
        ax1.set_xlabel('BIO1 (x 10 ¬∞C)')
        ax1.set_ylabel('Densidade')
        st.pyplot(fig1)
    
    with col2:
        # Dispers√£o BIO1 vs BIO12
        st.markdown("**Rela√ß√£o entre BIO1 e BIO12**")
        sample_data = df_clean.sample(n=min(5000, len(df_clean)), random_state=42)
        fig2, ax2 = plt.subplots()
        sns.scatterplot(x='bio12', y='bio1', data=sample_data, alpha=0.5, ax=ax2, color='darkred')
        ax2.set_title('BIO1 vs BIO12 (Amostra)')
        ax2.set_xlabel('BIO12 (mm)')
        ax2.set_ylabel('BIO1 (x 10 ¬∞C)')
        st.pyplot(fig2)
    
    # Gr√°ficos do modelo (se treinado)
    if st.session_state.get('model') is not None:
        st.subheader("Visualiza√ß√£o do Modelo")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribui√ß√£o dos res√≠duos
            residuals = st.session_state.test_data['y'] - st.session_state.predictions
            st.markdown("**Distribui√ß√£o dos Res√≠duos do Modelo**")
            fig3, ax3 = plt.subplots()
            sns.histplot(residuals, kde=True, ax=ax3, color='lightgreen')
            ax3.set_title('Distribui√ß√£o dos Res√≠duos')
            ax3.set_xlabel('Res√≠duos (y_test - y_pred)')
            ax3.set_ylabel('Densidade')
            st.pyplot(fig3)
        
        with col2:
            # Valores reais vs preditos
            st.markdown("**Valores Reais vs Preditos**")
            fig4, ax4 = plt.subplots()
            ax4.scatter(st.session_state.test_data['y'], st.session_state.predictions, 
                       alpha=0.5, color='purple')
            ax4.plot([st.session_state.test_data['y'].min(), st.session_state.test_data['y'].max()], 
                    [st.session_state.test_data['y'].min(), st.session_state.test_data['y'].max()], 
                    'r--', lw=2)
            ax4.set_xlabel('Valores Reais')
            ax4.set_ylabel('Valores Preditos')
            ax4.set_title('Valores Reais vs Preditos')
            st.pyplot(fig4)

# --- UI 5: Refer√™ncias (Mantida) ---

def ui_referencias():
    st.header("üìö Refer√™ncias Bibliogr√°ficas")
    
    st.markdown("""
    ### Base de Dados Utilizada
    
    **WorldClim - South America Climate Data**
    - **Fonte:** INPE (Instituto Nacional de Pesquisas Espaciais)
    - **URL:** [http://www.dpi.inpe.br/amb_data/AmericaSul/SAmerica_WCLIM.zip](http://www.dpi.inpe.br/amb_data/AmericaSul/SAmerica_WCLIM.zip)
    - **Descri√ß√£o:** Conjunto de dados bioclim√°ticos de alta resolu√ß√£o (1km) para a Am√©rica do Sul, contendo 19 vari√°veis bioclim√°ticas derivadas de dados de temperatura e precipita√ß√£o.
    
    ### Refer√™ncias Bibliogr√°ficas
    
    1. **Fick, S.E. & Hijmans, R.J. (2017)**  
       *WorldClim 2: new 1km spatial resolution climate surfaces for global land areas*  
       International Journal of Climatology
    
    2. **Wickham, H. & Grolemund, G. (2016)**  
       *R for Data Science*  
       O'Reilly Media
    
    3. **McKinney, W. (2017)**  
       *Python for Data Analysis*  
       O'Reilly Media
    
    4. **Streamlit Documentation (2023)**  
       [https://docs.streamlit.io](https://docs.streamlit.io)
    
    ### Vari√°veis Bioclim√°ticas (BIO1-BIO19)
    
    As 19 vari√°veis bioclim√°ticas representam aspectos anuais e sazonais do clima:
    - **BIO1:** Temperatura m√©dia anual
    - **BIO2:** Varia√ß√£o m√©dia diurna
    - **BIO3:** Isotermalidade
    - **BIO4:** Sazonalidade da temperatura
    - **BIO5:** Temperatura m√°xima do m√™s mais quente
    - **BIO6:** Temperatura m√≠nima do m√™s mais frio
    - **BIO7:** Amplitude t√©rmica anual
    - **BIO12:** Precipita√ß√£o anual
    - **BIO13:** Precipita√ß√£o do m√™s mais √∫mido
    - **BIO14:** Precipita√ß√£o do m√™s mais seco
    """)

# --- Aplica√ß√£o Principal (Atualizada) ---

def main():
    st.set_page_config(
        page_title="An√°lise Clim√°tica - Am√©rica do Sul",
        page_icon="üåé",
        layout="wide"
    )
    
    st.title("üåé An√°lise Clim√°tica da Am√©rica do Sul - Vers√£o Integrada")
    st.markdown("An√°lise de dados bioclim√°ticos do WorldClim usando Python e Streamlit")
    
    # Inicializar session state
    if 'processar_dados' not in st.session_state:
        st.session_state.processar_dados = False
    if 'dados_processados' not in st.session_state:
        st.session_state.dados_processados = False
    if 'df_clean' not in st.session_state:
        st.session_state.df_clean = None
    if 'model' not in st.session_state:
        st.session_state.model = None
    if 'metrics' not in st.session_state:
        st.session_state.metrics = None
    
    # Menu lateral
    st.sidebar.title("Navega√ß√£o")
    opcoes_menu = [
        "1. Administra√ß√£o - Download e Processamento",
        "2. An√°lise Estat√≠stica Explorat√≥ria", 
        "3. Modelagem: Regress√£o Linear M√∫ltipla",
        "4. Visualiza√ß√£o de Dados e Modelo",
        "5. Refer√™ncias"
    ]
    
    selecao = st.sidebar.radio("Selecione a se√ß√£o:", opcoes_menu)
    
    # Status do sistema na sidebar
    st.sidebar.markdown("---")
    st.sidebar.subheader("Status do Sistema")
    
    if st.session_state.get('dados_processados', False):
        st.sidebar.success("‚úÖ Dados Processados")
        st.sidebar.write(f"üìä {len(st.session_state.df_clean):,} pontos de dados")
    else:
        st.sidebar.warning("‚ö†Ô∏è Aguardando Processamento")
    
    # Navega√ß√£o entre se√ß√µes
    if selecao == opcoes_menu[0]:
        ui_administracao()
    elif selecao == opcoes_menu[1]:
        ui_analise_estatistica()
    elif selecao == opcoes_menu[2]:
        ui_modelagem()
    elif selecao == opcoes_menu[3]:
        ui_visualizacao()
    elif selecao == opcoes_menu[4]:
        ui_referencias()

if __name__ == "__main__":
    main()